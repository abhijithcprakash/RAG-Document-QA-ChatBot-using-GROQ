---

# ğŸ“„ Document Q&A Assistant 

An intelligent, PDF-powered Q&A chatbot built using **Streamlit**, **LangChain**, **Groq API (Llama3)**, and **FAISS** for vector search.  
Users can upload any PDF, embed its content, and ask questions â€” with answers generated using **RAG (Retrieval-Augmented Generation)**.

---

## âš™ï¸ Project Overview

### ğŸ§  How It Works

1. **PDF Upload**  
   User uploads a PDF document through the Streamlit interface.

2. **Text Extraction & Splitting**  
   Text is extracted using `PyPDFLoader`, and split into manageable chunks using `RecursiveCharacterTextSplitter`.

3. **Vector Embedding**  
   The text chunks are converted into embeddings using `OllamaEmbeddings` with the `gemma:2b` model and stored in **FAISS**, a fast vector search library.

4. **RAG-based Question Answering**  
   When the user asks a question:
   - The retriever finds relevant content chunks from the embedded document.
   - These are passed as context to a **Groq-hosted Llama3 model** to generate a smart answer.

5. **Frontend UI**  
   The Streamlit app provides a clean interface with real-time feedback and styled components for user-friendly interaction.

---

## ğŸ›  Tech Stack

- **Streamlit** â€“ UI and interactivity
- **LangChain** â€“ For chaining prompt logic and RAG
- **Groq API** â€“ LLM inference (Llama3-8b-8192)
- **OllamaEmbeddings** â€“ For document vectorization
- **FAISS** â€“ Vector similarity search
- **dotenv** â€“ Managing environment variables

---

## ğŸ“¦ Installation & Setup

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/document-qa-assistant.git
cd document-qa-assistant
```

### 2. Create a Virtual Environment
```bash
python -m venv venv
# Activate:
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate
```

### 3. Install Requirements
```bash
pip install -r requirements.txt
```

### 4. Create a `.env` File
Add your API keys in a `.env` file at the project root:

```
GROQ_API_KEY=your-groq-api-key
LANGCHAIN_API_KEY=your-langchain-api-key
HUGGINGFACE_API=your-huggingface-api-key
```
> âœ… **GROQ_API_KEY** is used to access Llama3 from Groq.

---

## ğŸš€ Running the App

```bash
streamlit run app.py
```

> Replace `app.py` with your actual script name if different.

---

## ğŸ’¡ Features

- ğŸ“¤ Upload any PDF
- âš¡ Smart document embedding with `gemma:2b`
- ğŸ¤– Intelligent responses using Llama3-8b via Groq API
- ğŸ” Retrieval-Augmented Generation (RAG)
- ğŸ¨ Beautiful, interactive UI
- ğŸ“š View the context retrieved from your document

---

## ğŸ” API Key Handling

- All API keys are securely loaded from `.env` using `python-dotenv`.
- No key is hardcoded in the script.
- Only the **Groq API Key** is used at runtime for LLM inference.

---


---

## ğŸ§ª Demo Workflow

1. Upload a PDF file.
2. Click **"ğŸ“š Embed Document"**.
3. Type your question in the input box.
4. Get your answer â€” backed by relevant context from the document.
---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---
